# MySQL笔记

### MySQL处理请求过程 

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200819135318396.png)

一次请求经过连接管理、查询缓存、语法解析、查询优化之后，调用具体的存储引擎（InnoDB等）API实现数据的真实存取

### 常用的指令（非查询语句）

- ```mysql
  SHOW ENGINES;       # 查看当前服务器程序支持的所有引擎
  ```

- ```mysql
  SHOW [GLOBAL|SESSION] VARIABLES [LIKE 匹配的模式];    # 查看系统变量的值
  ```

- ```mysql
  SET [GLOBAL|SESSION] 系统变量名 = 值;   # 设置系统变量的值，不指定作用范围默认session
  ```

- ```mysql
  SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];   # 查看系统状态
  ```

- 

### 启动选项和系统变量

#### 启动选项和配置文件

在启动MySQL时，通过配置文件和命令行参数实现控制MySQL的运行特性。

- 命令行参数：mysqld --default-storage-engine = MyISAM 

- 配置文件：MySQL按照如下的顺序加载配置文件，下面的配置会覆盖上面的配置

  ```
  路径名	备注
  /etc/my.cnf	
  /etc/mysql/my.cnf	
  SYSCONFDIR/my.cnf	
  $MYSQL_HOME/my.cnf	特定于服务器的选项（仅限服务器）
  defaults-extra-file	命令行指定的额外配置文件路径
  ~/.my.cnf	用户特定选项
  ~/.mylogin.cnf	用户特定的登录路径选项（仅限客户端）
  ```

- 在配置文件中，配置文件区分不同的选项，也就是对应下面表格对应的组；同样，MySQL有多种启动文件，如下图的启动命令显示，MySQL会按照如下的规则加载不同组的配置，如果不同的组中出现相同的配置，后面的组会覆盖前面的组

- | 启动命令       | 类别       | 能读取的组                               |
  | -------------- | ---------- | ---------------------------------------- |
  | `mysqld`       | 启动服务器 | `[mysqld]`、`[server]`                   |
  | `mysqld_safe`  | 启动服务器 | `[mysqld]`、`[server]`、`[mysqld_safe]`  |
  | `mysql.server` | 启动服务器 | `[mysqld]`、`[server]`、`[mysql.server]` |
  | `mysql`        | 启动客户端 | `[mysql]`、`[client]`                    |
  | `mysqladmin`   | 启动客户端 | `[mysqladmin]`、`[client]`               |
  | `mysqldump`    | 启动客户端 | `[mysqldump]`、`[client]`                |

#### 系统变量和系统状态

`MySQL`服务器程序运行过程中会用到许多影响程序行为的变量，它们被称为`MySQL`系统变量。通过配置文件和命令行启动时会指定部分系统变量的值，例如max_connections，有些系统变量是可以修改的，修改的范围又分为GLOBAL和SESSION两种不同的作用范围

##### 查看系统变量

```
SHOW [GLOBAL|SESSION] VARIABLES [LIKE 匹配的模式];
```

##### 设置系统变量

`系统变量`对于大部分系统变量来说，它们的值可以在服务器程序运行过程中进行动态修改而无需停止并重启服务器。系统变量的`作用范围`分为这两种：

- `GLOBAL`：全局变量，影响服务器的整体操作。
- `SESSION`：会话变量，影响某个客户端连接的操作。（注：`SESSION`有个别名叫`LOCAL`）

```
SET [GLOBAL|SESSION] 系统变量名 = 值;
SET [@@(GLOBAL|SESSION).]var_name = XXX;
```

```
例如：以下三种语句设置session作用范围的系统变量
语句一：SET SESSION default_storage_engine = MyISAM;
语句二：SET @@SESSION.default_storage_engine = MyISAM;
语句三：SET default_storage_engine = MyISAM;
```

##### 状态变量

为了让我们更好的了解服务器程序的运行情况，`MySQL`服务器程序中维护了好多关于程序运行状态的变量，它们被称为`状态变量`。比方说`Threads_connected`表示当前有多少客户端与服务器建立了连接，`Handler_update`表示已经更新了多少行记录吧啦吧啦，像这样显示服务器程序状态信息的`状态变量`还有好几百个，我们就不一一唠叨了，等遇到了会详细说它们的作用的。

由于`状态变量`是用来显示服务器程序运行状况的，所以它们的值只能由服务器程序自己来设置，我们程序员是不能设置的。与`系统变量`类似，`状态变量`也有`GLOBAL`和`SESSION`两个作用范围的，所以查看`状态变量`的语句可以这么写：

```
SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];
```

类似的，如果我们不写明作用范围，默认的作用范围是`SESSION`

### 字符集和比较规则

https://juejin.im/book/6844733769996304392/section/6844733770042441741

### InnoDB记录存储结构

InnoDB将表中的数据存储在磁盘中，实现数据持久化，而真正处理数据是在内存中的。`InnoDB`采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 ***16*** KB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。

#### InnoDB行格式

`InnoDB`存储引擎行格式共有4种不同类型的`行格式`，分别是`Compact`、`Redundant`、`Dynamic`和`Compressed`行格式，其中原理都近似

指定或者修改表中的行格式

```
CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称  
ALTER TABLE 表名 ROW_FORMAT=行格式名称
```

#### `Compact`行格式

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200819175143765.png)

- 变长字段长度列表：在`Compact`行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数按照列的顺序逆序存放，例如列1、列2、列3都为varchar、varbinary、TEXT、BlOB等变成格式，长度分别为0X04,0X03,0X01，那么变长字段长度列表存储的为01 03 04

- NULL值列表：如果某个列允许存储null，那么在null值列表中存储值为null的列信息，采用二进制存储00001001，倒序，通常一个字节，超出8个列则采用两字节。。。

- 记录头信息：`5`个字节也就是`40`个二进制位

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200819175636597.png)

|      名称      | 大小（单位：bit） |                      描述                      |
| :------------: | :---------------: | :--------------------------------------------: |
|   `预留位1`    |        `1`        |                    没有使用                    |
|   `预留位2`    |        `1`        |                    没有使用                    |
| `delete_mask`  |        `1`        |              标记该记录是否被删除              |
| `min_rec_mask` |        `1`        | B+树的每层非叶子节点中的最小记录都会添加该标记 |
|   `n_owned`    |        `4`        |            表示当前记录拥有的记录数            |
|   `heap_no`    |       `13`        |          表示当前记录在页面堆的位置信          |
| `record_type`  |         3         |                   记录的类型                   |
| `next_record`  |       `16`        |            表示下一条记录的相对位置            |
|                |                   |                                                |

1. delete_mask：用来表示当前这条记录是否已经被删除，0代表没被删除，1代表已经删除。所有被删除掉的记录都会组成一个所谓的`垃圾链表`，所有被删除的记录占用的空间称为可重用空间。当垃圾链表到达某种级别后，MySQL会执行删除的动作。

2. min_rec_mask：B+树的每条非叶子节点中的最小记录会添加该标记。

3. n_owned：表示当前记录拥有的记录数

4. heap_no：记录在当前页的位置，InnoDB会在heap_no为0和1的位置插入==最小记录==和==最大记录==（存储在`Infimum + Supremum`区域）的两条伪记录。我们插入的数据从2开始计数，通过主键的大小进行排序存储。

5. record_type：`0`表示普通记录，`1`表示B+树非叶节点记录，`2`表示最小记录，`3`表示最大记录

6. next_record：从当前记录的真实数据到下一条记录的真实数据的地址偏移量

   ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200820173132886.png)

   所以，不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。

- `MySQL`会为每个记录默认的添加一些列（也称为`隐藏列`）：row_id、transaction_id、roll_pointer(回滚指针)，InnoDB存储引擎会为每条记录都添加 ***transaction_id*** 和 ***roll_pointer*** 这两个列，但是 ***row_id*** 是可选的（在没有自定义主键以及Unique键的情况下才会添加该列）

#### 行溢出

MySQL采用页的形式存储行数据，页的大小 一般为 16K。存储的数据个数 可以用下面的公式计算。

其中132字节为页除了存放行数据之外还要存储的乱七八糟数据。

每条记录有27个字节保存了记录的信息，包括下边这些部分：

- 2个字节用于存储真实数据的长度
- 1个字节用于存储列是否是NULL值
- 5个字节大小的头信息
- 6个字节的`row_id`列
- 6个字节的`transaction_id`列
- 7个字节的`roll_pointer`列

除此之外，MySQL要求每页最少存储两条数据，所以计算一行记录的最大大小n必须满足 132 + 2×(27 + n) < 16384

求解这个式子得出的解是：`n < 8099`。也就是说如果一个列中存储的数据小于`8099`个字节，那么该列就不会成为`溢出列`，否则该列就需要成为`溢出列`。不过这个`8099`个字节的结论只是针对只有一个列的`varchar_size_demo`表来说的，如果表中有多个列，那上边的式子和结论都需要改一改了，所以重点就是：你不用关注这个临界点是什么，只要知道如果我们一条记录的某个列中存储的数据占用的字节数非常多时，该列就可能成为`溢出列`。

### InnoDB数据页结构

MySQL采用页的形式存储数据，数据页的16K的空间划分为下面7个部分。

|         名称         |       中文名       | 占用空间大小 |         简单描述         |
| :------------------: | :----------------: | :----------: | :----------------------: |
|    `File Header`     |      文件头部      |   `38`字节   |     页的一些通用信息     |
|    `Page Header`     |      页面头部      |   `56`字节   |   数据页专有的一些信息   |
| `Infimum + Supremum` | 最小记录和最大记录 |   `26`字节   |     两个虚拟的行记录     |
|    `User Records`    |      用户记录      |    不确定    |   实际存储的行记录内容   |
|     `Free Space`     |      空闲空间      |    不确定    |    页中尚未使用的空间    |
|   `Page Directory`   |      页面目录      |    不确定    | 页中的某些记录的相对位置 |
|    `File Trailer`    |      文件尾部      |   `8`字节    |      校验页是否完整      |


##### 页类型

|         类型名称          | 十六进制 |               描述               |
| :-----------------------: | :------: | :------------------------------: |
| `FIL_PAGE_TYPE_ALLOCATED` |  0x0000  |        最新分配，还没使用        |
|    `FIL_PAGE_UNDO_LOG`    |  0x0002  |            Undo日志页            |
|     `FIL_PAGE_INODE`      |  0x0003  |            段信息节点            |
| `FIL_PAGE_IBUF_FREE_LIST` |  0x0004  |      Insert Buffer空闲列表       |
|  `FIL_PAGE_IBUF_BITMAP`   |  0x0005  |        Insert Buffer位图         |
|    `FIL_PAGE_TYPE_SYS`    |  0x0006  |              系统页              |
|  `FIL_PAGE_TYPE_TRX_SYS`  |  0x0007  |           事务系统数据           |
|  `FIL_PAGE_TYPE_FSP_HDR`  |  0x0008  |          表空间头部信息          |
|   `FIL_PAGE_TYPE_XDES`    |  0x0009  |            扩展描述页            |
|   `FIL_PAGE_TYPE_BLOB`    |  0x000A  |              溢出页              |
|     `FIL_PAGE_INDEX`      |  0x45BF  | 索引页，也就是我们所说的`数据页` |

##### 有了上面记录的头信息的知识之后，看一下页的各个部分的描述：

- `User Records `用户的记录，通过insert语句存入数据，每当我们插入一条记录，都会从`Free Space`部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到`User Records`部分，当`Free Space`部分的空间全部被`User Records`部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了

- `Page Directory`表示当前页的目录。InnoDB将页中的数据分组，每个组的最后一条数据的n_owned存储组中的记录个数，将每一组最后面记录的地址偏移量数据存储在`Page Directory`中，这些偏移量数据称为slot槽

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200820174036341.png)

  `InnoDB`对每个分组中的记录条数是有规定的：对于最小记录所在的分组只能有 ***1*** 条记录，最大记录所在的分组拥有的记录条数只能在 ***1~8*** 条之间，剩下的分组中记录的条数范围只能在是 ***4~8*** 条之间

  有了页目录数据之后，在一个数据页中查找指定主键值的记录的过程分为两步：

  1. 通过二分法确定该记录所在的槽，并找到该槽所在分组中主键值最小的那条记录。
  2. 通过记录的`next_record`属性遍历该槽所在的组中的各个记录。

- `Page Header`描述一个数据页中存储的记录的状态信息，比如本页中已经存储了多少条记录，第一条记录的地址是什么，页目录中存储了多少个槽等等

- `File Header`它描述了一些针对各种页都通用的一些信息，例如页的编号，上一页下一页的信息，页的校验和，页的类型，页最后被修改的日志序列位置等

- `File Trailer`前4个字节代表页的校验和和后4个字节代表页面被最后修改时对应的日志序列位置（LSN），用于数据持久化时判断当前页是否持久化成功

综上：`InnoDB`数据页有7个组成部分，各个数据页可以组成一个`双向链表`，而每个数据页中的记录会按照主键值从小到大的顺序组成一个`单向链表`，每个数据页都会为存储在它里边儿的记录生成一个`页目录`，在通过主键查找某条记录的时候可以在`页目录`中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200820175501864.png)

### B+树索引

**页分裂**：在页中插入数据，页的`Free Space`不足之后，为了保证下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值，如果新插入数据的id处于当前页中间就需要新增加页存储数据。这个过程我们也可以称为`页分裂`。

为了提升数据的查找的速度，引入了索引，又称为目录页，目录页的每个目录项包括下边两个部分：

- 页的用户记录中最小的主键值，我们用`key`来表示。
- 页号，我们用`page_no`表示。

查找的时候首先通过二分查找的方式查找到主键在索引中的值，这个值就是数据存储页对应的页号，确定页号之后去页文件中查找，通过页文件的页目录通过二分查找到对应的数据槽然后遍历查找。

当页非常多的时候，一个索引页不能完全存储所有页的索引，所以需要更高一级的索引文件，最终形成多级的索引结构，如下图。其中非叶子节点（内节点）为索引页（目录项记录），叶子节点为用户实际存储的数据。这种结构就是B+树

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200820213138502.png)

#### 聚簇索引

上边的`B+`树本身就是一个目录，或者说本身就是一个索引。它有两个特点：

1. 使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义：

   - 页内的记录是按照主键的大小顺序排成一个单向链表。
   - 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。
   - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。

2. `B+`树的叶子节点存储的是完整的用户记录。

   所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。

我们把具有这两种特性的`B+`树称为`聚簇索引`，所有完整的用户记录都存放在这个`聚簇索引`的叶子节点处。这种`聚簇索引`并不需要我们在`MySQL`语句中显式的使用`INDEX`语句去创建（后边会介绍索引相关的语句），`InnoDB`存储引擎会自动的为我们创建聚簇索引。另外有趣的一点是，在`InnoDB`存储引擎中，`聚簇索引`就是数据的存储方式（所有的用户记录都存储在了`叶子节点`），也就是所谓的索引即数据，数据即索引。

#### 二级索引（辅助索引）

聚簇索引只有在搜索主键的时候才能发挥效果，因为聚簇索引中的数据都是按照主键从大到小的数据存储的。当搜索的条件不是主键的时候，只能全表扫描。为了提升其他字段搜索的效率，可以为这些经常查询的字段建立独立的B+树索引，称为二级索引（空间换时间）

- 使用记录`c2`列的大小进行记录和页的排序，这包括三个方面的含义：
  - 页内的记录是按照`c2`列的大小顺序排成一个单向链表。
  - 各个存放用户记录的页也是根据页中记录的`c2`列大小顺序排成一个双向链表。
  - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的`c2`列大小顺序排成一个双向链表。
- `B+`树的叶子节点存储的并不是完整的用户记录，而只是`c2列+主键`这两个列的值。
- 目录项记录中不再是`主键+页号`的搭配，而变成了`c2列+页号`的搭配。

二级索引的查找过程：

由于辅助索引中只存储辅助索引列和主键的值，所以首先通过二分查找找到搜索值对应的主键的值，如果我们想根据`c2`列的值查找到完整的用户记录的话，仍然需要到`聚簇索引`中再查一遍，这个过程也被称为`回表`。

#### 联合索引

我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引，比方说我们想让`B+`树按照`c2`和`c3`列的大小进行排序，这个包含两层含义：

- 先把各个记录和页按照`c2`列进行排序。
- 在记录的`c2`列相同的情况下，采用`c3`列进行排序

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200820214220498.png)

以c2和c3列的大小为排序规则建立的B+树称为联合索引，本质上也是一个二级索引。它的意思与分别为c2和c3列分别建立索引的表述是不同的，不同点如下：

- 建立`联合索引`只会建立如上图一样的1棵`B+`树。
- 为c2和c3列分别建立索引会分别以`c2`和`c3`列的大小为排序规则建立2棵`B+`树。

### B+树索引适用的条件

1. `B+`树索引在空间和时间上都有代价，所以没事儿别瞎建索引。
2. `B+`树索引适用于下边这些情况：
   - 全值匹配
   - 匹配左边的列
   - 匹配范围值
   - 精确匹配某一列并范围匹配另外一列
   - 用于排序
   - 用于分组
3. 在使用索引时需要注意下边这些事项：
   - 只为用于搜索、排序或分组的列创建索引
   - 为列的基数大的列创建索引
   - 索引列的类型尽量小
   - 可以只对字符串值的前缀建立索引
   - 只有索引列在比较表达式中单独出现才可以适用索引
   - 为了尽可能少的让`聚簇索引`发生页面分裂和记录移位的情况，建议让主键拥有`AUTO_INCREMENT`属性。
   - 定位并删除表中的重复和冗余索引
   - 尽量使用`覆盖索引`进行查询，避免`回表`带来的性能损耗。

### MySQL的数据目录

MySQL不管采用什么存储引擎，数据库的都是把表存储在文件系统（磁盘）上的。

查看当前数据库的数据目录位置

```mysql
SHOW VARIABLES LIKE 'datadir';
```

#### 数据库在文件系统中的表示

当我们通过create database语句创建一个数据库的时候，MySQL都会在数据目录位置下创建一个与数据库名相同的子文件夹

文件夹下的文件：

- db.opt文件，包含了该数据库的各种属性，比方说该数据库的字符集和比较规则是个啥。
- 表名.frm文件，描述表结构的文件，例如列信息，索引信息，比较规则等数据
- 表名.ibd， 独立表空间

除了上面的数据库对应的文件外，还包含系统表空间（这个所谓的`系统表空间`可以对应文件系统上一个或多个实际的文件，默认情况下，`InnoDB`会在`数据目录`下创建一个名为`ibdata1`（在你的数据目录下找找看有木有）、大小为`12M`的文件，这个文件就是对应的`系统表空间`在文件系统上的表示。怎么才`12M`？这么点儿还没插多少数据就用完了，哈哈，那是因为这个文件是所谓的`自扩展文件`，也就是当不够用的时候它会自己增加文件大小～），其他类型的表空间（通用表空间（general tablespace）、undo表空间（undo tablespace）、临时表空间（temporary tablespace）等），其他的文件（服务器进程文件， 服务器日志文件， 默认/自动生成的SSL和RSA证书和密钥文件）

### MySQL的系统数据库

- `mysql`

  这个数据库贼核心，它存储了MySQL的用户账户和权限信息，一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。

- `information_schema`

  这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。

- `performance_schema`

  这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多长时间，内存的使用情况等等信息。

- `sys`

  这个数据库主要是通过视图的形式把`information_schema`和`performance_schema`结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。

### InnoDB的表空间

#### 独立表空间

==页==16k      表中的页太多了，为了方便管理，64个页组成一个==区==占用1M空间        连续的256个区定义为一个==组==         

那碎片区是什么呢？当分配数据的时候，通过区分配空间会造成浪费，所以抽象出一个碎片区的概念，碎片区直接录属于表空间，所以此后为某个段分配存储空间的策略是这样的：

- 在刚开始向表中插入数据的时候，段是从某个碎片区以单个页面为单位来分配存储空间的。
- 当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间。

==段== 索引将叶子节点和非叶子节点分为两个段存储，每个段包含了很多个区，区又构成组，段不能仅定义为是某些区的集合，更精确的应该是某些零散的页面以及一些完整的区的集合。

区呢分为4种，包括空闲区、有剩余空间的碎片区、没有剩余空间的碎片区、附属于某个段的区（前面三种对应碎片区）

XDES Entry 是什么呢？是描述一个区的信息属性的结构，区种类，区ID，并且存储了上一个区和下一个区的地址，以便形成链表

XDES Entry的pre和next指针形成的==链表==有什么意义呢，将不同类型的区连接起来，存到==段==的INODE信息中，这样就能在段中访问到区了

链表基节点 ==List Base Node==呢？存储的就是当前的链表的基础信息喽

**上面的总结一下就是：**

表空间是由若干个区组成的，每个区都对应一个`XDES Entry`的结构，直属于表空间的区对应的`XDES Entry`结构可以分成`FREE`、`FREE_FRAG`和`FULL_FRAG`这3个链表；每个段可以附属若干个区，每个段中的区对应的`XDES Entry`结构可以分成`FREE`、`NOT_FULL`和`FULL`这3个链表。每个链表都对应一个`List Base Node`的结构，这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数。正是因为这些链表的存在，管理这些区才变成了一件so easy的事情。

==FSP_HDR== 是啥呢？表空间的第一个页面，存储的是整个表空间整体的属性以及组内256个区的对应的`XDES Entry`结构

#### 系统表空间

系统表空间存储结构和独立表空间类似，多了下面这些信息。

| 页号 | 页面类型  |        英文描述        | 描述                        |
| :--: | :-------: | :--------------------: | :-------------------------- |
| `3`  |   `SYS`   |  Insert Buffer Header  | 存储Insert Buffer的头部信息 |
| `4`  |  `INDEX`  |   Insert Buffer Root   | 存储Insert Buffer的根页面   |
| `5`  | `TRX_SYS` |   Transction System    | 事务系统的相关信息          |
| `6`  |   `SYS`   | First Rollback Segment | 第一个回滚段的页面          |
| `7`  |   `SYS`   | Data Dictionary Header | 数据字典头部信息            |

除了这几个记录系统属性的页面之外，系统表空间的`extent 1`和`extent 2`这两个区，也就是页号从`64`~`191`这128个页面被称为`Doublewrite buffer`，也就是双写缓冲区。

Double write 是InnoDB在 tablespace上的128个页（2个区）是2MB；

#### InnoDB的数据字典

InnoDB存储引擎特意定义了一些列的内部系统表（internal system table）来记录这些这些`元数据`：

|        表名        |                            描述                            |
| :----------------: | :--------------------------------------------------------: |
|    `SYS_TABLES`    |             整个InnoDB存储引擎中所有的表的信息             |
|   `SYS_COLUMNS`    |             整个InnoDB存储引擎中所有的列的信息             |
|   `SYS_INDEXES`    |            整个InnoDB存储引擎中所有的索引的信息            |
|    `SYS_FIELDS`    |        整个InnoDB存储引擎中所有的索引对应的列的信息        |
|   `SYS_FOREIGN`    |            整个InnoDB存储引擎中所有的外键的信息            |
| `SYS_FOREIGN_COLS` |         整个InnoDB存储引擎中所有的外键对应列的信息         |
| `SYS_TABLESPACES`  |            整个InnoDB存储引擎中所有的表空间信息            |
|  `SYS_DATAFILES`   | 整个InnoDB存储引擎中所有的表空间对应文件系统的文件路径信息 |
|   `SYS_VIRTUAL`    |         整个InnoDB存储引擎中所有的虚拟生成列的信息         |

这些系统表也被称为`数据字典`，它们都是以`B+`树的形式保存在系统表空间的某些页面中，其中`SYS_TABLES`、`SYS_COLUMNS`、`SYS_INDEXES`、`SYS_FIELDS`这四个表尤其重要，称之为基本系统表（basic system tables）

##### Data Dictionary Header页面

`InnoDB`采用个固定的页面来记录这4个表的聚簇索引和二级索引对应的`B+树`位置，这个页面就是页号为`7`的页面，类型为`SYS`，记录了`Data Dictionary Header`，也就是数据字典的头部信息。除了这4个表的5个索引的根页面信息外，这个页号为`7`的页面还记录了整个InnoDB存储引擎的一些全局属性

##### information_schema系统数据库

需要注意一点的是，用户是不能直接访问`InnoDB`的这些内部系统表的，除非你直接去解析系统表空间对应文件系统上的文件。不过设计InnoDB的大叔考虑到查看这些表的内容可能有助于大家分析问题，所以在系统数据库`information_schema`中提供了一些以`innodb_sys`开头的表,在`information_schema`数据库中的这些以`INNODB_SYS`开头的表并不是真正的内部系统表（内部系统表就是我们上边唠叨的以`SYS`开头的那些表），而是在存储引擎启动时读取这些以`SYS`开头的系统表，然后填充到这些以`INNODB_SYS`开头的表中。以`INNODB_SYS`开头的表和以`SYS`开头的表中的字段并不完全一样，但是可以看一下

### 单表访问方法

索引具体可以划分为聚簇索引、唯一二级索引、普通二级索引、聚合索引。

设计`MySQL`的大叔把`MySQL`执行查询语句的方式称之为`访问方法`或者`访问类型`

#### const

把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为：`const`。这种`const`访问方法只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效，如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个`const`访问方法才有效。

#### ref

比较好理解，也就是针对普通的索引如果通过等值比较，在二级索引中查询到多条记录，如下，这种查询的效率比const低，但是低的有限，这种方式策划功能为ref。

ref是针对 where name = 'wang' 和 where name is null类似的查询语句

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200821162555169.png)

#### ref_or_null

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200821163230794.png)

#### range

类似于下面的查询语句

SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 >= 38 AND key2 <= 79);

#### index

假设在表中存在idx_part1_part2_part3，在下面的查询中只查询联合索引中的值，而且查询的条件不符合最左原则，但是联合索引的数据量小，所以采用index的执行方式

SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = 'abc';

#### all

全表扫描

### 索引合并

#### Intersection合并

SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';

例如上述表中存在idx_key1和idx_key3，那么MySQL会首先采用两个二级索引查询结果的交集回表查询。`Intersection`翻译过来的意思是`交集`。这里是说某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集。

#### Union合并

SELECT * FROM single_table WHERE key1 = 'a' OR key3 = 'b'

`Intersection`是交集的意思，这适用于使用不同索引的搜索条件之间使用`AND`连接起来的情况；`Union`是并集的意思，适用于使用不同索引的搜索条件之间使用`OR`连接起来的情况。与`Intersection`索引合并类似，`MySQL`在某些特定的情况下才可能会使用到`Union`索引合并

#### Sort-Union合并

`Union`索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到`Union`索引合并：

```
SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z'
```

这是因为根据`key1 < 'a'`从`idx_key1`索引中获取的二级索引记录的主键值不是排好序的，根据`key3 > 'z'`从`idx_key3`索引中获取的二级索引记录的主键值也不是排好序的，但是`key1 < 'a'`和`key3 > 'z'`这两个条件又特别让我们动心，所以我们可以这样：

- 先根据`key1 < 'a'`条件从`idx_key1`二级索引中获取记录，并按照记录的主键值进行排序
- 再根据`key3 > 'z'`条件从`idx_key3`二级索引中获取记录，并按照记录的主键值进行排序
- 因为上述的两个二级索引主键值都是排好序的，剩下的操作和`Union`索引合并方式就一样了。

我们把上述这种先按照二级索引记录的主键值进行排序，之后按照`Union`索引合并方式执行的方式称之为`Sort-Union`索引合并，很显然，这种`Sort-Union`索引合并比单纯的`Union`索引合并多了一步对二级索引记录的主键值排序的过程。



### 连接的原理

`连接`的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户，这样到的集合叫做笛卡尔积。

#### 连接的大致过程

```mysql
SELECT * FROM t1, t2 WHERE t1.m1 > 1 AND t1.m1 = t2.m2 AND t2.n2 < 'd';
```

对于如上的查询语句，t1被称为驱动表，t2被称为被驱动表；

首先在t1的驱动表中查询到符合要求的条件——> 在t2表中扫描获取符合t1.m1 = t2.m2和t2.n2 < 'd'的数据，共需要查询一次t1表和2次t2表，如下：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200824113052993.png)

#### 内连接和外连接

- 对于`内连接`的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入到最后的结果集，我们上边提到的连接都是所谓的`内连接`。

- 对于`外连接`的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。外连接分为左连接和右连接，只不过是指定驱动表是左边的或者右边的表罢了。

查询中对被驱动表使用主键值或者唯一二级索引列的值进行等值查找的查询执行方式称之为：`eq_ref`。

Where 和 On 的条件有什么区别？

- 对于内连接而言，where和on的作用一样。
- 对于外连接，on关键字的意义在于：如果驱动表中的数据在被驱动表中找不到，同样会加入到结果集中，会用null值填充。外连接强制要求有on。而where可以在on的过滤基础之上进行过滤筛选。

#### 嵌套循环连接

假如三表连接，这个过程就像是一个嵌套的循环，驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为`嵌套循环连接`（`Nested-Loop Join`），这是最简单，也是最笨拙的一种连接查询算法。

#### 使用索引加快连接速度

针对被驱动表的查询字段建立索引，以提升被驱动表的查询速度

####  基于块的嵌套循环连接（Block Nested-Loop Join）

`join buffer`就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个`join buffer`中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和`join buffer`中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的`I/O`代价。使用`join buffer`的过程如下图所示：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200824114416928.png)

最好的情况是`join buffer`足够大，能容纳驱动表结果集中的所有记录，这样只需要访问一次被驱动表就可以完成连接操作了。设计`MySQL`的大叔把这种加入了`join buffer`的嵌套循环连接算法称之为`基于块的嵌套连接`（Block Nested-Loop Join）算法。

这个`join buffer`的大小是可以通过启动参数或者系统变量`join_buffer_size`进行配置，默认大小为`262144字节`（也就是`256KB`），最小可以设置为`128字节`。当然，对于优化被驱动表的查询来说，最好是为被驱动表加上效率高的索引，如果实在不能使用索引，并且自己的机器的内存也比较大可以尝试调大`join_buffer_size`的值来对连接查询进行优化。

### 成本优化

MySQL执行一个SQL查询有多种执行方案，他们会选择其中成本最低的方案执行。在MySQL中一条查询语句的成本分为两部分：

- `I/O`成本：这个从磁盘到内存这个加载的过程损耗的时间称之为`I/O`成本。
- `CPU`成本：读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为`CPU`成本。

对于`InnoDB`存储引擎来说，页是磁盘和内存之间交互的基本单位，设计`MySQL`的大叔规定读取一个页面花费的成本默认是`1.0`，读取以及检测一条记录是否符合搜索条件的成本默认是`0.2`。1.0和0.2被称为==成本常数==。

在一条单表查询语句真正执行之前，`MySQL`的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的`执行计划`，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样：

1. 根据搜索条件，找出所有可能使用的索引
2. 计算全表扫描的代价
3. 计算使用不同索引执行查询的代价
4. 对比各种执行方案的代价，找出成本最低的那一个

#### 单表成本的计算方案

##### 第一步：==possible keys== 一次执行过程中可能用到的索引

对于`B+`树索引来说，只要索引列和常数使用`=`、`<=>`、`IN`、`NOT IN`、`IS NULL`、`IS NOT NULL`、`>`、`<`、`>=`、`<=`、`BETWEEN`、`!=`（不等于也可以写成`<>`）或者`LIKE`操作符连接起来，就可以产生一个所谓的`范围区间`（`LIKE`匹配字符串前缀也行），也就是说这些搜索条件都可能使用到索引，设计`MySQL`的大叔把一个查询中可能使用到的索引称之为`possible keys`。

##### 第二步：计算全表扫描的代价

想要计算全表扫描首先需要知道 ==当前表的索引页数==、==该表中的记录数==。这两个数据可以通过show table status like '表名'；

表中的Rows代表行数      Data_length/16/1024 代表页数

所以全表扫描的成本近似可以计算为：**1.0 * 页数 + 0.2 * 行数 **

##### 第三步：计算不同索引的代价

考虑的情况是    **采用每个单个索引的成本和是否索引合并以及成本**，对于二级索引+回表的查询方式，成本依赖于 **范围区间数量** 和 **需要回表的记录数**

- 范围区间数量（读取二级索引） ： MySQL粗暴认为 一个范围区间内的I/O成本和读取一个页面是相同的。例如对于区间(10, 1000)，I/O成本为1.0；对于key1 IN ('a', 'b', 'c') 来讲，I/O成本为3.0
- 需要回表的记录数（通过二级索引搜索主键数据）：对于二级索引的回表成本为 确定回表的数据个数 + 回表数据主键数据搜索（CPU成本）。首先对于统计区间内的回表记录数的时间成本可以忽略不计。那么假设对于区间(10, 1000)，我们统计区间内数据的个数为95，那么这95条数据的二级索引付出的CPU成本为 95 * 0.2

- 到聚簇索引中做回表操作：MySQL规定，每次回表的操作成本，都相当于访问一个页面，对于上面我们有95条数据需要回表，那么I/O成本就为 95 * 1.0；接下来的操作是根据主键的值进行数据检索，也就是CPU操作，成本为 95 * 0.2

所以对于单表辅助索引的成本近似就是 ==1.0 + 95 * 0.2 + 95 * 1.0 + 95 * 0.2== 约等于 130

##### 第四步：索引合并

在计算执行成本的时候需要考虑索引合并的情况，也就是计算基于索引合并的成本。

##### 第五步：对比各种执行方案的代价，找出成本最低的那一个

找到执行成本最低的方案，执行数据查询。

#### 基于索引统计数据的成本计算

我们在统计回表数据个数时，如果是连续的区间，可以通过层级更高的B+数节点中的数据协助统计，设计`MySQL`的大叔把这种通过直接访问索引对应的`B+`树来计算某个范围区间对应的索引记录条数的方式称之为`index dive`。，采用 in (a, b, c) 关键字的数据统计时，如果in中的条件非常多，这时候统计回表个数的成本就会很高

考虑到了这种情况，所以提供了一个系统变量`eq_range_index_dive_limit`，默认情况下`eq_range_index_dive_limit`的值为200，也就是当in中的`index dive`多于200时，此时MySQL会根据表的统计数据来估算回表记录个数。

- 使用`SHOW TABLE STATUS`展示出的`Rows`值，也就是一个表中有多少条记录。

  这个统计数据我们在前边唠叨全表扫描成本的时候说过很多遍了，就不赘述了。

- 使用`SHOW INDEX`语句展示出的`Cardinality`属性。

  结合上一个`Rows`统计数据，我们可以针对索引列，计算出平均一个值重复多少次。

  ```
  一个值的重复次数 ≈ Rows ÷ Cardinality
  ```

那此时如果计算出一个值重复的次数为10，那么需要回表的记录数据条数大约为 ==10 * in中的value的个数==

#### 连接查询的成本

假设我们此时有两张表 t1和t2，假设t1为连接查询的驱动表，t2就是被驱动表

所以连接查询的查询成本由下边两个部分构成：

- 单次查询驱动表的成本
- 多次查询被驱动表的成本（具体查询多少次取决于对驱动表查询的结果集中有多少条记录）

我们把对驱动表进行查询后得到的记录条数称之为驱动表的`扇出`（英文名：`fanout`）。很显然驱动表的扇出值越小，对被驱动表的查询次数也就越少，连接查询的总成本也就越低。当查询优化器想计算整个连接查询所使用的成本时，就需要计算出驱动表的扇出值。

计算驱动表的扇出有时候可以很简单的统计出来，有序后需要靠猜，这个猜的过程非常繁琐，设计`MySQL`把这个`猜`的过程称之为`condition filtering`

连接查询的成本计算公式是这样的：

```
连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 * 单次访问被驱动表的成本
```

从上边的计算过程也可以看出来，连接查询成本占大头的其实是`驱动表扇出数 x 单次访问被驱动表的成本`，所以我们的优化重点其实是下边这两个部分：

- 尽量减少驱动表的扇出

- 对被驱动表的访问成本尽量低

  这一点对于我们实际书写连接查询语句时十分有用，我们需要尽量在被驱动表的连接列上建立索引，这样就可以使用`ref`访问方法来降低访问被驱动表的成本了。如果可以，被驱动表的连接列最好是该表的主键或者唯一二级索引列，这样就可以把访问被驱动表的成本降到更低了。

本节详见：https://juejin.im/book/6844733769996304392/section/6844733770055024647



### InnoDB统计数据的收集

`InnoDB`提供了两种存储统计数据的方式：

- 永久性的统计数据

  这种统计数据存储在磁盘上，也就是服务器重启之后这些统计数据还在。

- 非永久性的统计数据

  这种统计数据存储在内存中，当服务器关闭时这些这些统计数据就都被清除掉了，等到服务器重启之后，在某些适当的场景下才会重新收集这些统计数据。

MySQl中目前版本 innodb_stats_persistent 变量默认为on，也就是默认采用永久性的统计数据

存储统计数据的方式可以在建表时手动指定

```mysql
CREATE TABLE 表名 (...) Engine=InnoDB, STATS_PERSISTENT = (1|0);
```

总结：

- `InnoDB`以表为单位来收集统计数据，这些统计数据可以是基于磁盘的永久性统计数据，也可以是基于内存的非永久性统计数据。
- `innodb_stats_persistent`控制着使用永久性统计数据还是非永久性统计数据；`innodb_stats_persistent_sample_pages`控制着永久性统计数据的采样页面数量；`innodb_stats_transient_sample_pages`控制着非永久性统计数据的采样页面数量；`innodb_stats_auto_recalc`控制着是否自动重新计算统计数据。
- 我们可以针对某个具体的表，在创建和修改表时通过指定`STATS_PERSISTENT`、`STATS_AUTO_RECALC`、`STATS_SAMPLE_PAGES`的值来控制相关统计数据属性。
- `innodb_stats_method`决定着在统计某个索引列不重复值的数量时如何对待`NULL`值。

感觉没啥干货，具体地址：https://juejin.im/book/6844733769996304392/section/6844733770055041031

### 子连接优化

这小节看的不是很清楚，但是大多是都是MySQL针对子查询语句的优化，具体：https://juejin.im/book/6844733769996304392/section/6844733770059218951

- 如果`IN`子查询符合转换为`semi-join`的条件，查询优化器会优先把该子查询转换为`semi-join`，然后再考虑下边5种执行半连接的策略中哪个成本最低：

  - Table pullout
  - DuplicateWeedout
  - LooseScan
  - Materialization
  - FirstMatch

  选择成本最低的那种执行策略来执行子查询。

- 如果`IN`子查询不符合转换为`semi-join`的条件，那么查询优化器会从下边两种策略中找出一种成本更低的方式执行子查询：

  - 先将子查询物化之后再执行查询
  - 执行`IN to EXISTS`转换。

#### ANY/ALL子查询优化

如果ANY/ALL子查询是不相关子查询的话，它们在很多场合都能转换成我们熟悉的方式去执行，比方说：

|          原始表达式           |             转换为             |
| :---------------------------: | :----------------------------: |
| < ANY (SELECT inner_expr ...) | < (SELECT MAX(inner_expr) ...) |
| > ANY (SELECT inner_expr ...) | > (SELECT MIN(inner_expr) ...) |
| < ALL (SELECT inner_expr ...) | < (SELECT MIN(inner_expr) ...) |
| > ALL (SELECT inner_expr ...) | > (SELECT MAX(inner_expr) ...) |



#### [NOT] EXISTS子查询的执行

如果`[NOT] EXISTS`子查询是不相关子查询，可以先执行子查询，得出该`[NOT] EXISTS`子查询的结果是`TRUE`还是`FALSE`，并重写原先的查询语句，比如对这个查询来说：

```
SELECT * FROM s1 
    WHERE EXISTS (SELECT 1 FROM s2 WHERE key1 = 'a') 
        OR key2 > 100;
```

因为这个语句里的子查询是不相关子查询，所以优化器会首先执行该子查询，假设该EXISTS子查询的结果为`TRUE`，那么接着优化器会重写查询为：

```
SELECT * FROM s1 
    WHERE TRUE OR key2 > 100;
```

进一步简化后就变成了：

```
SELECT * FROM s1 
    WHERE TRUE;
```

对于相关的`[NOT] EXISTS`子查询来说，比如这个查询：

```
SELECT * FROM s1 
    WHERE EXISTS (SELECT 1 FROM s2 WHERE s1.common_field = s2.common_field);
```

很不幸，这个查询只能按照我们年少时的那种执行相关子查询的方式来执行。不过如果`[NOT] EXISTS`子查询中如果可以使用索引的话，那查询速度也会加快不少，比如：

```
SELECT * FROM s1 
    WHERE EXISTS (SELECT 1 FROM s2 WHERE s1.common_field = s2.key1);
```

上边这个`EXISTS`子查询中可以使用`idx_key1`来加快查询速度。

#### 对于派生表的优化

我们前边说过把子查询放在外层查询的`FROM`子句后，那么这个子查询的结果相当于一个`派生表`，比如下边这个查询：

```
SELECT * FROM  (
        SELECT id AS d_id,  key3 AS d_key3 FROM s2 WHERE key1 = 'a'
    ) AS derived_s1 WHERE d_key3 = 'a';
```

子查询`( SELECT id AS d_id, key3 AS d_key3 FROM s2 WHERE key1 = 'a')`的结果就相当于一个派生表，这个表的名称是`derived_s1`，该表有两个列，分别是`d_id`和`d_key3`。

对于含有`派生表`的查询，`MySQL`提供了两种执行策略：

- 最容易想到的就是把派生表物化。

  我们可以将派生表的结果集写到一个内部的临时表中，然后就把这个物化表当作普通表一样参与查询。当然，在对派生表进行物化时，设计`MySQL`的大叔使用了一种称为`延迟物化`的策略，也就是在查询中真正使用到派生表时才回去尝试物化派生表，而不是还没开始执行查询呢就把派生表物化掉。比方说对于下边这个含有派生表的查询来说：

  ```
  SELECT * FROM (
          SELECT * FROM s1 WHERE key1 = 'a'
      ) AS derived_s1 INNER JOIN s2
      ON derived_s1.key1 = s2.key1
      WHERE s2.key2 = 1;
  ```

  如果采用物化派生表的方式来执行这个查询的话，那么执行时首先会到`s2`表中找出满足`s2.key2 = 1`的记录，如果压根儿找不到，说明参与连接的`s2`表记录就是空的，所以整个查询的结果集就是空的，所以也就没有必要去物化查询中的派生表了。

- 将派生表和外层的表合并，也就是将查询重写为没有派生表的形式

  我们来看这个贼简单的包含派生表的查询：

  ```
  SELECT * FROM (SELECT * FROM s1 WHERE key1 = 'a') AS derived_s1;
  ```

  这个查询本质上就是想查看`s1`表中满足`key1 = 'a'`条件的的全部记录，所以和下边这个语句是等价的：

  ```
  SELECT * FROM s1 WHERE key1 = 'a';
  ```

  对于一些稍微复杂的包含派生表的语句，比如我们上边提到的那个：

  ```
  SELECT * FROM (
          SELECT * FROM s1 WHERE key1 = 'a'
      ) AS derived_s1 INNER JOIN s2
      ON derived_s1.key1 = s2.key1
      WHERE s2.key2 = 1;
  ```

  我们可以将派生表与外层查询的表合并，然后将派生表中的搜索条件放到外层查询的搜索条件中，就像这样：

  ```
  SELECT * FROM s1 INNER JOIN s2 
      ON s1.key1 = s2.key1
      WHERE s1.key1 = 'a' AND s2.key2 = 1;
  ```

  这样通过将外层查询和派生表合并的方式成功的消除了派生表，也就意味着我们没必要再付出创建和访问临时表的成本了。可是并不是所有带有派生表的查询都能被成功的和外层查询合并，当派生表中有这些语句就不可以和外层查询合并：

  - 聚集函数，比如MAX()、MIN()、SUM()啥的
  - DISTINCT
  - GROUP BY
  - HAVING
  - LIMIT
  - UNION 或者 UNION ALL
  - 派生表对应的子查询的`SELECT`子句中含有另一个子查询
  - ... 还有些不常用的情况就不多说了哈～

所以`MySQL`在执行带有派生表的时候，优先尝试把派生表和外层查询合并掉，如果不行的话，再把派生表物化掉执行查询。



### Explain && optimizer trace

这两个部分可能需要回锅

### Buffer Pool

当我们读取数据时，首先访问Buffer Pool的缓存，如果缓存中存在寻找的页，直接通过hash找到页数据，否则在磁盘中读取页数据到内存中，由于磁盘太慢，用内存作为缓存很有必要。

`Buffer Pool`本质上是`InnoDB`向操作系统申请的一段连续的内存空间，可以通过`innodb_buffer_pool_size`来调整它的大小，默认128M；

为了管理缓冲池中的页数据：采用以下的结构进行存储，控制块存储控制信息包括该页所属的表空间编号、页号、缓存页在`Buffer Pool`中的地址、链表节点信息、一些锁信息以及`LSN`信息；控制块和缓存页是一一对应的，它们都被存放到 Buffer Pool 中，其中控制块被存放到 Buffer Pool 的前边，缓存页被存放到 Buffer Pool 后边；在填充足够多的控制块和缓存页的组合后，`Buffer Pool`剩余的空间可能产生不够填充一组控制块和缓存页，这部分空间不能被使用，也被称为`碎片`。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200826141451109.png)

##### 链表

`InnoDB`使用了许多`链表`来管理`Buffer Pool`，包括很多，如free链表、flush链表、LRU链表，`unzip LRU链表`用于管理解压页，`zip clean链表`用于管理没有被解压的压缩页，`zip free数组`中每一个元素都代表一个链表，它们组成所谓的`伙伴系统`来为压缩页提供内存空间等等

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200826142102208.png)

链表的结构如上所示，每个链表会有一个基节点，用来存储链表的基本信息。

##### 缓存页的hash处理

用`表空间号 + 页号`作为`key`，`缓存页`作为`value`创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据`表空间号 + 页号`看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从`free链表`中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。

##### LRU链表

InnoDB采用链表的结构存储缓存数据，简单理解为当页为热点数据，排在链表的头部，长时间没被访问到的页面数据排在链表后面，缓冲池中的空间不够时，淘汰尾部数据。但是问题在于全表扫描和数据的预读机制会导致上述的方案失效。所以：

`LRU链表`分为`young`和`old`两个区域，可以通过`innodb_old_blocks_pct`来调节`old`区域所占的比例。首次从磁盘上加载到`Buffer Pool`的页会被放到`old`区域的头部，在`innodb_old_blocks_time`（在对某个处在`old`区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该页面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部）间隔时间内访问该页不会把它移动到`young`区域头部。在`Buffer Pool`没有可用的空闲缓存页时，会首先淘汰掉`old`区域的一些页。

除此之外，通过缓存页位于`young`区域的`1/4`的后边，才会被移动到`LRU链表`头部，这样就可以降低调整`LRU链表`的频率，从而提升性能（也就是说如果某个缓存页对应的节点在`young`区域的`1/4`中，再次访问该缓存页时也不会将其移动到`LRU`链表头部）的方式提升LRU链表的整体性能。

`young`和`old`两个区域的比例可以通过innodb_old_blocks_pct来调节

##### 多个Buffer Pool实例

`Buffer Pool`本质是`InnoDB`向操作系统申请的一块连续的内存空间，在多线程环境下，访问`Buffer Pool`中的各种链表都需要加锁处理啥的，在`Buffer Pool`特别大而且多线程并发访问特别高的情况下，单一的`Buffer Pool`可能会影响请求的处理速度。所以在`Buffer Pool`特别大的时候，我们可以把它们拆分成若干个小的`Buffer Pool`，每个`Buffer Pool`都称为一个`实例`，它们都是独立的，独立的去申请内存空间，独立的管理各种链表，独立的吧啦吧啦，所以在多线程并发访问时并不会相互影响，从而提高并发处理能力。我们可以在服务器启动的时候通过设置`innodb_buffer_pool_instances`的值来修改`Buffer Pool`实例的个数，比方说这样：

```
[server]
innodb_buffer_pool_instances = 2
```

这样就表明我们要创建2个`Buffer Pool`实例，示意图就是这样：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200826143258622.png)

当innodb_buffer_pool_size的值小于1G的时候设置多个实例是无效的，InnoDB会默认把innodb_buffer_pool_instances 的值修改为1。而我们鼓励在`Buffer Pool`大于或等于1G的时候设置多个`Buffer Pool`实例。

##### innodb_buffer_pool_chunk_size

在`MySQL 5.7.5`之前，`Buffer Pool`的大小只能在服务器启动时通过配置`innodb_buffer_pool_size`启动参数来调整大小，在服务器运行过程中是不允许调整该值的。不过设计`MySQL`的大叔在`5.7.5`以及之后的版本中支持了在服务器运行过程中调整`Buffer Pool`大小的功能，但是有一个问题，就是每次当我们要重新调整`Buffer Pool`大小时，都需要重新向操作系统申请一块连续的内存空间，然后将旧的`Buffer Pool`中的内容复制到这一块新空间，这是极其耗时的。所以设计`MySQL`的大叔们决定不再一次性为某个`Buffer Pool`实例向操作系统申请一大片连续的内存空间，而是以一个所谓的`chunk`为单位向操作系统申请空间。也就是说一个`Buffer Pool`实例其实是由若干个`chunk`组成的，一个`chunk`就代表一片连续的内存空间，里边儿包含了若干缓存页与其对应的控制块，画个图表示就是这样：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200826143501319.png)

上图代表的`Buffer Pool`就是由2个实例组成的，每个实例中又包含2个`chunk`。

正是因为发明了这个`chunk`的概念，我们在服务器运行期间调整`Buffer Pool`的大小时就是以`chunk`为单位增加或者删除内存空间，而不需要重新向操作系统申请一片大的内存，然后进行缓存页的复制。这个所谓的`chunk`的大小是我们在启动操作`MySQL`服务器时通过`innodb_buffer_pool_chunk_size`启动参数指定的，它的默认值是`134217728`，也就是`128M`。不过需要注意的是，innodb_buffer_pool_chunk_size的值只能在服务器启动时指定，在服务器运行过程中是不可以修改的。

> 小贴士： 为什么不允许在服务器运行过程中修改innodb_buffer_pool_chunk_size的值？还不是因为innodb_buffer_pool_chunk_size的值代表InnoDB向操作系统申请的一片连续的内存空间的大小，如果你在服务器运行过程中修改了该值，就意味着要重新向操作系统申请连续的内存空间并且将原先的缓存页和它们对应的控制块复制到这个新的内存空间中，这是十分耗时的操作！ 另外，这个innodb_buffer_pool_chunk_size的值并不包含缓存页对应的控制块的内存空间大小，所以实际上InnoDB向操作系统申请连续内存空间时，每个chunk的大小要比innodb_buffer_pool_chunk_size的值大一些，约5%。

##### 查看Buffer Pool的状态信息

```
SHOW ENGINE INNODB STATUS\G
```

具体见：https://juejin.im/book/6844733769996304392/section/6844733770063429646

### 事务的简介

#### ACID

- 原子性（Atomicity）：现实世界中转账操作是一个不可分割的操作，也就是说要么压根儿就没转，要么转账成功，不能存在中间的状态，也就是转了一半的这种情况。设计数据库的大叔们把这种要么全做，要么全不做的规则称之为`原子性`

- 一致性（Consistency）：数据库总是从一个符合正确状态转换到另一个正确的状态

- 隔离性（Isolation）：其他的状态转换不会影响到本次状态的转换

- 永久性（Durability）：当一个状态转换之后，转换的结果将永久的保留。

#### 事务的状态

- 活动的（active）

  事务对应的数据库操作正在执行过程中时，我们就说该事务处在`活动的`状态。

- 部分提交的（partially committed）

  当事务中的最后一个操作执行完成，但由于操作都在内存中执行，所造成的影响并没有刷新到磁盘时，我们就说该事务处在`部分提交的`状态。

- 失败的（failed）

  当事务处在`活动的`或者`部分提交的`状态时，可能遇到了某些错误（数据库自身的错误、操作系统错误或者直接断电等）而无法继续执行，或者人为的停止当前事务的执行，我们就说该事务处在`失败的`状态。

- 中止的（aborted）

  如果事务执行了半截而变为`失败的`状态，比如我们前边唠叨的狗哥向猫爷转账的事务，当狗哥账户的钱被扣除，但是猫爷账户的钱没有增加时遇到了错误，从而当前事务处在了`失败的`状态，那么就需要把已经修改的狗哥账户余额调整为未转账之前的金额，换句话说，就是要撤销失败事务对当前数据库造成的影响。书面一点的话，我们把这个撤销的过程称之为`回滚`。当`回滚`操作执行完毕时，也就是数据库恢复到了执行事务之前的状态，我们就说该事务处在了`中止的`状态。

- 提交的（committed）

  当一个处在`部分提交的`状态的事务将修改过的数据都同步到磁盘上之后，我们就可以说该事务处在了`提交的`状态。

#### 事务的隐式提交

如果在一个事务中有如下的语句，会导致当前的事务隐式提交。

- DDL语句

  当我们使用`CREATE`、`ALTER`、`DROP`等语句去修改这些所谓的数据库对象时，就会隐式的提交前边语句所属于的事务，就像这样：

- 隐式使用或修改`mysql`数据库中的表

  当我们使用`ALTER USER`、`CREATE USER`、`DROP USER`、`GRANT`、`RENAME USER`、`REVOKE`、`SET PASSWORD`等语句时也会隐式的提交前边语句所属于的事务。

- 事务控制或关于锁定的语句

  当我们在一个事务还没提交或者回滚时就又使用`START TRANSACTION`或者`BEGIN`语句开启了另一个事务时，会隐式的提交上一个事务

- 加载数据的语句

  比如我们使用`LOAD DATA`语句来批量往数据库中导入数据时，也会隐式的提交前边语句所属的事务。

- 关于`MySQL`复制的一些语句

  使用`START SLAVE`、`STOP SLAVE`、`RESET SLAVE`、`CHANGE MASTER TO`等语句时也会隐式的提交前边语句所属的事务。

- 其它的一些语句

  使用`ANALYZE TABLE`、`CACHE INDEX`、`CHECK TABLE`、`FLUSH`、 `LOAD INDEX INTO CACHE`、`OPTIMIZE TABLE`、`REPAIR TABLE`、`RESET`等语句也会隐式的提交前边语句所属的事务。

#### 保存点

SAVEPOINT

https://juejin.im/book/6844733769996304392/section/6844733770063609869

### redo日志

##### 什么是redo日志

我们在往数据库写数据的时候，首先需要将磁盘中的页缓存到内存中的Buffer Pool中，然后修改Buffer Pool中的页面。假设后续的事务提交时，发生了故障，导致内存中的数据全部丢失了，这时候修改的数据没有持久化到磁盘中，导致数据的丢失。那如果每次提交事务都将脏页刷到磁盘中呢？这样刷一整页太浪费，而且采用随机I/O的话，性能很低。

我们的目的是想让事务提交的数据永久生效，即使系统崩溃，在重启之后数据也能恢复回来，这样就满足了持久性的要求。当系统恢复之后按照数据更新记录的步骤重新更新数据页，那么这个记录的文件称为==重做日志==，也就是redo log==\==>记录了事务对数据库做了哪些修改。那么使用redo log与每次将修改的页面刷到磁盘的方式相比有什么优势呢？

- redo的日志占用空间小，每一条redo log 的日志占用的空间都不是很大
- redo日志是顺序写入磁盘的，也就是使用顺序I/O

##### redo日志格式

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827102345655.png)

- type：日志类型
- space ID：表空间号
- page number：页号
- data：该条`redo`日志的具体内容

当我们插入一条数据的时候，可能表没有主键，需要生成一个row_id，或者导致表分裂、索引的变更等等，也就是说，一条语句可能会生成很多条redo的日志。MySQL提供了多中的redo日志格式用于存储不同的数据。这些日志有着两个层面的意思：

- 物理层面看，这些日志都指明了对哪个表空间的哪个页进行了修改。
- 逻辑层面看，在系统崩溃重启时，并不能直接根据这些日志里的记载，将页面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将页面恢复成系统崩溃前的样子。

以MLOG_COMP_REC_INSERT类型的redo log日志记录为例

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827104421280.png)

`redo`日志并没有记录`PAGE_N_DIR_SLOTS`的值修改为了啥，`PAGE_HEAP_TOP`的值修改为了啥，`PAGE_N_HEAP`的值修改为了啥等等这些信息，而只是把在本页面中插入一条记录所有必备的要素记了下来，之后系统崩溃重启时，服务器会调用相关向某个页面插入一条记录的那个函数，而`redo`日志中的那些数据就可以被当成是调用这个函数所需的参数，在调用完该函数后，页面中的`PAGE_N_DIR_SLOTS`、`PAGE_HEAP_TOP`、`PAGE_N_HEAP`等等的值也就都被恢复到系统崩溃前的样子了。这就是所谓的`逻辑`日志的意思。

##### Mini-Transaction

对于数据插入，可能一条插入伴随着一条redo 日志的生成，也可能伴随着多条日志的生成。在记录日志的时候，应该讲这一组数据存储在一起，而不是分开存储。InnoDB采用一个MLOG_MULTI_REC_END类型的redo日志记录来表明这是一组日志的结尾，也就是对应于一个原子操作的日志。在恢复的时候，读取到了MLOG_MULTI_REC_END，才会恢复之前一组的日志。对于一条redo日志，采用type字段的最高位是否为1来判断。

规定对底层页面中的一次原子访问的过程称之为一个`Mini-Transaction`，简称`mtr`，比如修改一次`Max Row ID`的值算是一个`Mini-Transaction`，向某个索引对应的`B+`树中插入一条记录的过程也算是一个`Mini-Transaction`。一个所谓的`mtr`可以包含一组`redo`日志，在进行崩溃恢复时这一组`redo`日志作为一个不可分割的整体。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827105303621.png)


##### redo日志的写入

一个mtr会产生多个redo日志，当mtr结束时，这一组redo日志会被复制到`log buffer`中

在写redo日志时，不能将数据直接写入磁盘，实际上在系统启动时向系统申请了一大块称为redo log buffer的空间（block是存储redo日志的512B的页）。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827105842300.png)

一个事务可能产生多个mtr，这些mtr可能交替写入redo日志缓冲

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827110127989.png)

如下，buf_free用来表示当前redo日志缓冲的插入位置，不同的事务的mtr交替插入。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827110317877.png)

##### redo日志刷盘时机

redo日志在redo log buffer也就是内存中呆着也不是事儿，所以需要将数据刷到磁盘中。刷盘的情况如下：

- `log buffer`空间不足时，日志量已经占满了`log buffer`总容量的大约一半左右，就需要把这些日志刷新到磁盘上。
- 事务提交时，为了保证持久性，必须要把修改这些页面对应的`redo`日志刷新到磁盘。
- 后台线程不停的刷刷刷，大约每秒都会刷新一次`log buffer`中的`redo`日志到磁盘。
- 正常关闭服务器时
- 做所谓的`checkpoint`时
- 其他的一些情况...

##### redo日志文件组

- `innodb_log_group_home_dir`

  该参数指定了`redo`日志文件所在的目录，默认值就是当前的数据目录。

- `innodb_log_file_size`

  该参数指定了每个`redo`日志文件的大小，在`MySQL 5.7.21`这个版本中的默认值为`48MB`，

- `innodb_log_files_in_group`

  该参数指定`redo`日志文件的个数，默认值为2，最大值为100。

这些文件以`ib_logfile[数字]`（`数字`可以是`0`、`1`、`2`...）的形式进行命名

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827111043556.png)

##### redo日志文件格式

将log buffer中的redo日志刷新到磁盘的本质就是把block的镜像写入日志文件中，所以`redo`日志文件其实也是由若干个`512`字节大小的block组成。`redo`日志文件组中的每个文件大小都一样，格式也一样，都是由两部分组成：

- 前2048个字节，也就是前4个block是用来存储一些管理信息的。
- 从第2048字节往后是用来存储`log buffer`中的block镜像的。

前2048个字节的结构如下：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827111752482.png)

- `log file header`：描述该`redo`日志文件的一些整体属性，包含LOG_HEADER_START_LSN标记本`redo`日志文件开始的LSN值，和一些其他信息

- `checkpoint1` ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827112120570.png)

- `checkpoint2` : 和checkpoint1一样

##### Log Sequence Number

InnoDB为记录已经写入的`redo`日志量，设计了一个称之为`Log Sequence Number`的全局变量，翻译过来就是：`日志序列号`，简称`lsn`。不过不像人一出生的年龄是`0`岁，`InnoDB`规定初始的`lsn`值为`8704`（也就是一条`redo`日志也没写入时，`lsn`的值为`8704`）。`lsn`是表示当前系统中写入的`redo`日志量，这包括了写到`log buffer`而没有刷新到磁盘的日志

当某个mtr执行完毕，生成redo日志，就会导致lsn的增长，lsn的初始值为8074，`lsn`增长的量就是该`mtr`生成的`redo`日志占用的字节数加上额外占用的`log block header`和`log block trailer`的字节数![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827112851604.png)

结论：==每一组由mtr生成的redo日志都有一个唯一的LSN值与其对应，LSN值越小，说明redo日志产生的越早。==

##### flushed_to_disk_lsn

设计`InnoDB`提出了一个表示刷新到磁盘中的`redo`日志量的全局变量，称之为`flushed_to_disk_lsn`。对应关系如下图：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827114000049.png)

综上所述，当有新的`redo`日志写入到`log buffer`时，首先`lsn`的值会增长，但`flushed_to_disk_lsn`不变，随后随着不断有`log buffer`中的日志被刷新到磁盘上，`flushed_to_disk_lsn`的值也跟着增长。如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。

##### flush链表中的LSN

当mtr结束时，会将一组redo log写到redo log buffer中，除此之外，还需要将把在mtr执行过程中可能修改过的页面加入到Buffer Pool的flush链表。

在flush链表中，在页的控制块中有两个记录两个关于页面何时修改的属性：

- `oldest_modification`：如果某个页面被加载到`Buffer Pool`后进行第一次修改，那么就将修改该页面的`mtr`开始时对应的`lsn`值写入这个属性。
- `newest_modification`：每修改一次页面，都会将修改该页面的`mtr`结束时对应的`lsn`值写入这个属性。也就是说该属性表示页面最近一次修改后对应的系统`lsn`值。

flush链表中的脏页按照修改发生的时间顺序进行排序，也就是按照oldest_modification代表的LSN值进行排序，被多次更新的页面不会重复插入到flush链表中，但是会更新newest_modification属性的值。

##### checkpoint

redo日志只是为了系统崩溃后恢复脏页用的，如果对应的脏页已经刷新到了磁盘，也就是说即使现在系统崩溃，那么在重启后也用不着使用redo日志恢复该页面了，所以该redo日志也就没有存在的必要了，那么它占用的磁盘空间就可以被后续的redo日志所重用。也就是说：判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是它对应的脏页是否已经刷新到磁盘里。

设计`InnoDB`提出了一个全局变量`checkpoint_lsn`来代表当前系统中可以被覆盖的`redo`日志总量是多少，这个变量初始值也是`8704`。

当flush list中某一页如页a数据被刷到了磁盘之后，那么redo log中页a的数据就可以被覆盖了，所以我们可以进行一个增加`checkpoint_lsn`的操作，我们把这个过程称做一次==checkpoint==

- 步骤一：计算一下当前系统中可以被覆盖的`redo`日志对应的`lsn`值最大是多少。

  `redo`日志可以被覆盖，意味着它对应的脏页被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏页对应的`oldest_modification`值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志都是可以被覆盖掉的，我们就把该脏页的`oldest_modification`赋值给`checkpoint_lsn`。

  比方说当前系统中`页a`已经被刷新到磁盘，那么`flush链表`的尾节点就是`页c`，该节点就是当前系统中最早修改的脏页了，它的`oldest_modification`值为8916，我们就把8916赋值给`checkpoint_lsn`（也就是说在redo日志对应的lsn值小于8916时就可以被覆盖掉）。

- 步骤二：将`checkpoint_lsn`和对应的`redo`日志文件组偏移量以及此次`checkpint`的编号写到日志文件的管理信息（就是`checkpoint1`或者`checkpoint2`）中。

  设计`InnoDB`的大叔维护了一个目前系统做了多少次`checkpoint`的变量`checkpoint_no`，每做一次`checkpoint`，该变量的值就加1。我们前边说过计算一个`lsn`值对应的`redo`日志文件组偏移量是很容易的，所以可以计算得到该`checkpoint_lsn`在`redo`日志文件组中对应的偏移量`checkpoint_offset`，然后把这三个值都写到`redo`日志文件组的管理信息中。

  我们说过，每一个`redo`日志文件都有`2048`个字节的管理信息，但是上述关于checkpoint的信息只会被写到日志文件组的第一个日志文件的管理信息中。不过我们是存储到`checkpoint1`中还是`checkpoint2`中呢？设计`InnoDB`的大叔规定，当`checkpoint_no`的值是偶数时，就写到`checkpoint1`中，是奇数时，就写到`checkpoint2`中。
![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200827144733094.png)


##### innodb_flush_log_at_trx_commit的用法

我们前边说为了保证事务的`持久性`，用户线程在事务提交时需要将该事务执行过程中产生的所有`redo`日志都刷新到磁盘上。这一条要求太狠了，会很明显的降低数据库性能。如果有的同学对事务的`持久性`要求不是那么强烈的话，可以选择修改一个称为`innodb_flush_log_at_trx_commit`的系统变量的值，该变量有3个可选的值：

- `0`：当该系统变量值为0时，表示在事务提交时不立即向磁盘中同步`redo`日志，这个任务是交给后台线程做的。

  这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将`redo`日志刷新到磁盘，那么该事务对页面的修改会丢失。

- `1`：当该系统变量值为1时，表示在事务提交时需要将`redo`日志同步到磁盘，可以保证事务的`持久性`。`1`也是`innodb_flush_log_at_trx_commit`的默认值。

- `2`：当该系统变量值为2时，表示在事务提交时需要将`redo`日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。

  这种情况下如果数据库挂了，操作系统没挂的话，事务的`持久性`还是可以保证的，但是操作系统也挂了的话，那就不能保证`持久性`了。

##### 崩溃恢复

1. 确定崩溃恢复的起点：崩溃恢复的起点是checkpoint_lsn，我们当然是要选取最近发生的那次checkpoint的信息。衡量`checkpoint`发生时间早晚的信息就是所谓的`checkpoint_no`，我们只要把`checkpoint1`和`checkpoint2`这两个block中的`checkpoint_no`值读出来比一下大小，哪个的`checkpoint_no`值更大，说明哪个block存储的就是最近的一次`checkpoint`信息。这样我们就能拿到最近发生的`checkpoint`对应的`checkpoint_lsn`值以及它在`redo`日志文件组中的偏移量`checkpoint_offset`。
2. 恢复的终点就是block的log block body属性的值不为`512`，它就是此次崩溃恢复中需要扫描的最后一个block。
3. 恢复：根据`redo`日志的`space ID`和`page number`属性计算出散列值，把`space ID`和`page number`相同的`redo`日志放到哈希表的同一个槽里，如果有多个`space ID`和`page number`都相同的`redo`日志，那么它们之间使用链表连接起来，按照生成的先后顺序链接起来的。之后就可以遍历哈希表，因为对同一个页面进行修改的`redo`日志都放在了一个槽里，所以可以一次性将一个页面修复好（避免了很多读取页面的随机IO），这样可以加快恢复速度。

##### redolog的二阶段提交



### undo日志

在事务没有完全执行完成之前，发生了错误或者用户手动回滚，为了保证事务的原子性，必须对事务已经修改了的数据进行回滚。

针对数据的改动，采用一个叫做undo log的文件存储数据改动之前的旧值，例如插入数据在undo log中存储主键id，删除数据和更新数据存储之前的旧值，这个文件称为==undo日志==

#### 事务id

开启事务的语句：

- 开启只读事务：start transaction read only
- 开启读写事务：start transaction read write 、 begain 、start transaction

事务id的分配：

- 对于只读事务，只有在第一次对用户创建的临时表进行数据增删改的时候，才会给事务分配一个事务id
- 对于读写事务，在对用户表第一次增删改操作时才会给事务分配一个事务id。如果读写事务中全是查询操作，则不分配事务id

事务id的生成：

- 事务id本质上就是一个数字，这个数字是一个全局的变量。每当这个数字是256的倍数时，就讲这个数据刷新到磁盘空间的5号页面的Max Trx ID的属性处，当系统重新启动后，就会读取Max Trx ID的值 + 256作为新的事务id，保证事务id的自增

这里再记录一下一条数据记录的格式：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200921104006619.png)

其中的trx_id就是对这个聚簇索引记录作修改的语句所在的事务的事务id

roll_pointer是指向记录对应的回滚日志记录的指针



数据的删除过程：主要分为两个阶段

- delete mark：第一个阶段仅仅将数据记录的delete_mask标志设置为1，其他的不做修改。这时候数据没有加入垃圾链表，中间状态

- purge：当删除的数据所在的事务提交之后，会有专门的线程将数据真正的删除，删除的过程就是将数据从正常的记录链表中移除，添加到垃圾链表中，然后更新页的信息，如记录数量、垃圾链表头节点等信息。这个过程称为purge

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200921111110702.png)



undo日志的格式：

- insert：比较简单，主要包括回滚日志对应的记录的表id、原始值信息、回滚日志类型

- delete：删除的undo日志和insert日志相比，首先，delete的unndo日志记录了所有字段的字段长度和旧值，另外多了几个重要的字段，最主要的是old trx_id、 old roll_pointer。在对一条记录进行`delete mark`操作前，需要把该记录的旧的`trx_id`和`roll_pointer`隐藏列的值都给记到对应的`undo日志`中来，就是我们图中显示的`old trx_id`和`old roll_pointer`属性。这样有一个好处，那就是可以通过`undo日志`的`old roll_pointer`找到记录在修改之前对应的`undo`日志。比方说在一个事务中，我们先插入了一条记录，然后又执行对该记录的删除操作，这个过程的示意图就是这样：

 ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200921112559594.png)

  这样，针对insert和delete操作就形成了一个undo日志的链表，这个链表被称为==版本链==。

- update：更新操作分为两种情况，更新主键和不更新主键。

  - 不更新主键：首先日志的格式和delete格式相似。对于不更新主键又分为数据的大小有没有变化，如果数据长度都一样，采用就地更新的方式更新数据；如果数据长度不一样，则在用户线程同步的删除原来的数据(不是标记，而是直接删除)，然后插入新数据，如果可以用free空间，则使用free空间，如果free存储空间，则页分裂存储。
  - 更新主键：针对更新主键的情况，过程和上面的不更新主键不一样。过程为首先将原有数据的delete mark置为1，然后将新id的数据插入到正确的位置。这里不直接删除之前记录的原因是MVCC。和上面的不更新主键的undo日志相比需要在undo日志中添加索引列各列信息数据。其他的和上述一样。



undo页面链表

- undo日志采用链表存储，innodb将undo日志分为两种，一种是insert类型，其他所有的算一种(分两种的原因是insert类型的数据可以随时被删除，而其他的数据需要支持MVCC服务)。数据是分页存储的，两种数据分别存储在两种不同的数据页中，日志数据紧凑和排列在一页之中，同一个事务的不同版本链采用链表的形式互相关联。

 ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922092744537.png)

- 对于单个事务而言，一条事务可以产生多条undo日志，并且可能同时包含insert和update两大类的日志，除此之外，事务对于临时表的操作同样也会产生两个大类的undo日志，所以一个事务的undo日志可能如下图所示。多条日志采用链表的形式存储，每个链表存储在一个单独的undo页面上。链表采用按需分配的原则，在事务一开始的时候不会分配链表，只有真正用到之后才会分配。

 ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922093114714.png)

- 对于没有被重用的`Undo页面`链表来说，链表的第一个页面，也就是`first undo page`在真正写入`undo日志`前，会填充`Undo Page Header`、`Undo Log Segment Header`、`Undo Log Header`这3个部分，之后才开始正式写入`undo日志`。对于其他的页面来说，也就是`normal undo page`在真正写入`undo日志`前，只会填充`Undo Page Header`。链表的`List Base Node`存放到`first undo page`的`Undo Log Segment Header`部分，`List Node`信息存放到每一个`Undo页面`的`undo Page Header`部分，所以画一个`Undo页面`链表的示意图就是这样

 ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922094227959.png)

- 每个undo页面存储的是一个事务的一种事务的链表，但是如果事务之产生了很少的undo日志，就会导致页面空间的浪费。为了减少空间浪费，所以针对每个页面进行一定程度的重用。重用的原则是：

  - 链表只占用了一个undo页面且已使用的空间小于整个页面的3/4
  - 针对已经提交的insert的undo日志，从头覆盖就好了，针对update的undo日志，不能覆盖，需要append已有的日志后面



回滚段

- 一个事务在执行的过程中最多可以分配4个undo页面链表，所以同一时刻系统中存在很多的undo页面链表，为了便于管理这些链表，InnoDB采用一个叫做Rollback Segment Header的页面，其中存储了各个undo页面链表的first undo page的页号，这些页号称为undo slot。每一个Rollback Segment Header页面对应一个段，这个段就是Rollback Segment，被称为回滚段。
- 在一开始的时候回滚段的undo slot不指向任何的地址，为一个特殊的FIL_NULL，随着时间的流逝，开始有事务需要分配undo链表，就从第一个undo slot开始，判断是不是FIL_NULL。如果不是FIL_NULL，那就在表空间创建一个新的undo log segment，然后从中申请一个页面作为undo页面链表的first undo page，然后把undo slot的值设置为first undo page，也就是将这个undo slot分配给这个事务。如果不为FIL_NULL，就向下搜索，如果1024个slot都不为空，则报错，意思是同时执行的事务数量超出规定的数量。此时可以重试，说不准此时有其他的事务已经提交，部分undo slot已经被释放了。
- 提交事务对应的undo slot有两种结果，如果undo页面链表符合重用的规则，则将这个页面加入到缓存链表中，接下来的事务先从缓存链表中查找可用的页面，如果有则优先使用，然后再去Rollback Segment Header中找。如果不符合重用规则，对于insert类型的链表对应的段会被释放掉，如果是update类型的undo链表，然后将本次事务写入的一组undo日志放到所谓的History链表中
- 多个回滚段：一个回滚段只有1024个undo slot，也就是只能支持1024个事务。InnoDB一共有128个Rollback Segment Header，也就是128个回滚段。这128个页面的地址统一存储在系统表空间的5号页面的128个8字节大小的格子。所以通过上边的叙述我们可以大致清楚，在系统表空间的第`5`号页面中存储了128个`Rollback Segment Header`页面地址，每个`Rollback Segment Header`就相当于一个回滚段。在`Rollback Segment Header`页面中，又包含`1024`个`undo slot`，每个`undo slot`都对应一个`Undo页面`链表。

为事务分配Undo页面链表详细过程

- 事务在执行过程中对普通表的记录首次做改动之前，首先会到系统表空间的第`5`号页面中分配一个回滚段（其实就是获取一个`Rollback Segment Header`页面的地址）。一旦某个回滚段被分配给了这个事务，那么之后该事务中再对普通表的记录做改动时，就不会重复分配了。

  使用传说中的`round-robin`（循环使用）方式来分配回滚段。比如当前事务分配了第`0`号回滚段，那么下一个事务就要分配第`33`号回滚段，下下个事务就要分配第`34`号回滚段，简单一点的说就是这些回滚段被轮着分配给不同的事务（就是这么简单粗暴，没啥好说的）。

- 在分配到回滚段后，首先看一下这个回滚段的两个`cached链表`有没有已经缓存了的`undo slot`，比如如果事务做的是`INSERT`操作，就去回滚段对应的`insert undo cached链表`中看看有没有缓存的`undo slot`；如果事务做的是`DELETE`操作，就去回滚段对应的`update undo cached链表`中看看有没有缓存的`undo slot`。如果有缓存的`undo slot`，那么就把这个缓存的`undo slot`分配给该事务。

- 如果没有缓存的`undo slot`可供分配，那么就要到`Rollback Segment Header`页面中找一个可用的`undo slot`分配给当前事务。

  从`Rollback Segment Header`页面中分配可用的`undo slot`的方式我们上边也说过了，就是从第`0`个`undo slot`开始，如果该`undo slot`的值为`FIL_NULL`，意味着这个`undo slot`是空闲的，就把这个`undo slot`分配给当前事务，否则查看第`1`个`undo slot`是否满足条件，依次类推，直到最后一个`undo slot`。如果这`1024`个`undo slot`都没有值为`FIL_NULL`的情况，就直接报错喽（一般不会出现这种情况）～

- 找到可用的`undo slot`后，如果该`undo slot`是从`cached链表`中获取的，那么它对应的`Undo Log Segment`已经分配了，否则的话需要重新分配一个`Undo Log Segment`，然后从该`Undo Log Segment`中申请一个页面作为`Undo页面`链表的`first undo page`。

- 然后事务就可以把`undo日志`写入到上边申请的`Undo页面`链表了！

### 事务隔离级别与MVCC

MySQL采用的也是B/S架构，服务端同时处理很多客户端的访问

事务并发执行遇到的问题：

- 脏写：一个事务修改了另一个未提交事务修改过的数据
- 脏读：一个事务读到了另一个未提交事务修改过的数据
- 不可重复读：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值
- 幻读：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来

SQL标准中的4种事务隔离级别：

- `READ UNCOMMITTED`：未提交读。隔离级别下，可能发生`脏读`、`不可重复读`和`幻读`问题。
- `READ COMMITTED`：已提交读。隔离级别下，可能发生`不可重复读`和`幻读`问题，但是不可以发生`脏读`问题。
- `REPEATABLE READ`：可重复读。隔离级别下，可能发生`幻读`问题，但是不可以发生`脏读`和`不可重复读`的问题。
- `SERIALIZABLE`：可串行化。隔离级别下，各种问题都不可以发生。

MySQL的默认事务隔离级别是`REPEATABLE READ`， 可以解决幻读问题的发生，同时脏写这个问题太严重了，无论哪种隔离级别都不允许发生

设置隔离级别语句：

- SET GLOBAL TRANSACTION ISOLATION LEVEL SERIALIZABLE;        对执行完这句语句的会话起作用，对于当前的会话无效
- SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;      对当前会话的后续语句有效，如果在正在执行的语句中执行，对于当前语句无效
- SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;      只对这个语句执行完成的下一个语句有效，不能在已经开启的事务中执行

#### MVCC原理

##### 版本链

首先一条数据的示意图如下：其中包含两个隐藏的字段trx_id和roll_pointer，trx_id是记录对应的事务id，roll_pointer指向undo log。undo log只在回滚的时候有用，当事务提交了，undo log就没用了，真正的undo log空间也会被回收

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922160916495.png)

每次对记录的改动，都会记录一条undo log，每条undo日志也会有一个roll_pointer属性，可以将这些roll_pointer连接起来，形成版本链，版本链的头节点就是这条记录的最新信息。

##### read view

对于使用read uncommited隔离级别来说，由于可以读取未提交的数据，直接读取数据的最新版本就好了；对于SERIALIZABLE隔离级别来讲，InnoDB采用加锁的方式来访问。而对于read commited和repreatable read来说，都必须保证读取到已经提交的数据，两种隔离级别的区别就在于==需要判断一下版本链中，那个版本的数据是当前事务可见的==

为此，InnoDB提出了read view的概念，在read view中主要包含4个比较重要的内容：

- `m_ids`：表示在生成`ReadView`时当前系统中活跃的读写事务的`事务id`列表。
- `min_trx_id`：表示在生成`ReadView`时当前系统中活跃的读写事务中最小的`事务id`，也就是`m_ids`中的最小值。
- `max_trx_id`：表示生成`ReadView`时系统中应该分配给下一个事务的`id`值。
- `creator_trx_id`：表示生成该`ReadView`的事务的`事务id`。

有了这个`ReadView`，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：

- 如果被访问版本的`trx_id`属性值与`ReadView`中的`creator_trx_id`值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
- 如果被访问版本的`trx_id`属性值小于`ReadView`中的`min_trx_id`值，表明生成该版本的事务在当前事务生成`ReadView`前已经提交，所以该版本可以被当前事务访问。
- 如果被访问版本的`trx_id`属性值大于或等于`ReadView`中的`max_trx_id`值，表明生成该版本的事务在当前事务生成`ReadView`后才开启，所以该版本不可以被当前事务访问。
- 如果被访问版本的`trx_id`属性值在`ReadView`的`min_trx_id`和`max_trx_id`之间，那就需要判断一下`trx_id`属性值是不是在`m_ids`列表中，如果在，说明创建`ReadView`时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建`ReadView`时生成该版本的事务已经被提交，该版本可以被访问。

read commited和repreatable read最大的区别就在于==生成read view的时机不同==：

- READ COMMITTED —— 每次读取数据前都生成一个ReadView
- REPEATABLE READ —— 在第一次读取数据时生成一个ReadView

##### 小结

从上边的描述中我们可以看出来，所谓的`MVCC`（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SELECT`操作时访问记录的版本链的过程，这样子可以使不同事务的`读-写`、`写-读`操作并发执行，从而提升系统性能。`READ COMMITTD`、`REPEATABLE READ`这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。

### 锁

#### 并发访问相同记录的情况大致可以分为三种情况

- 读 - 读： 这种情况数据不会发生变化，不会引起什么影响

- 写 - 写： 在多个未提交的事务相继对一条数据做改动时，需要采用锁让他们排队。大概的过程是：当事务想要对记录进行改动时，首先会看看在内存中是否已经有与这条记录相关的锁结构，没有的话就会生成一个锁结构与之关联。锁结构中主要的信息主要包括trx信息和锁的状态（是否等待）。如果已经有锁了，也创建一个锁结构与这条数据关联，不过锁的状态is_wating为true，这种场景称为获取锁失败或者加锁失败。当之前的事务提交之后，就会把锁结构释放掉，然后看还有没有其他的事务在获取锁，如果有，则将这个锁的状态is_wating置为false，然后唤醒事务对应的线程。

 ![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922191921034.png)

- 读 - 写： 

#### 解决脏读、不可重复读、幻读的两种解决方案

##### MVCC

读操作通过MVCC多版本并发控制，写操作加锁。普通的SELECT语句在READ COMMITTED和REPEATABLE READ隔离级别下会使用到MVCC读取记录。在READ COMMITTED隔离级别下，一个事务在执行过程中每次执行SELECT操作时都会生成一个ReadView，ReadView的存在本身就保证了事务不可以读取到未提交的事务所做的更改，也就是避免了脏读现象；REPEATABLE READ隔离级别下，一个事务在执行过程中只有第一次执行SELECT操作才会生成一个ReadView，之后的SELECT操作都复用这个ReadView，这样也就避免了不可重复读和幻读的问题。

##### 读写都采用加锁的方式

如果我们某些场景不允许读老版本的数据，而是每次必须去读取最新的数据，这样在读取数据的时候也需要加锁，也就是读操作和写操作也需要像写 - 写操作那样排队。

如果另一个事务在写操作的时候就对记录进行加锁操作，那么当前事务就不能读取这条数据，自然就不会发生脏读的问题

如果事务在读取事务的时候就对记录加锁，其他事务就无法修改内容了，自然就不会发生不可重复读

对于幻读，采用

##### 小结

对于以上两种方法各有优势，MVCC的性能高，但是在某些特殊的场景下必须采用加锁的方案。

#### 一致性读

事务利用`MVCC`进行的读取操作称之为`一致性读`，或者`一致性无锁读`，有的地方也称之为`快照读`。所有普通的`SELECT`语句（`plain SELECT`）在`READ COMMITTED`、`REPEATABLE READ`隔离级别下都算是`一致性读`。`一致性读`并不会对表中的任何记录做`加锁`操作，其他事务可以自由的对表中的记录做改动。

#### 锁定读

锁定读分为共享锁和独占锁。

- `共享锁`，英文名：`Shared Locks`，简称`S锁`。在事务要读取一条记录时，需要先获取该记录的`S锁`。LOCK IN SHARE MODE
- `独占锁`，也常称`排他锁`，英文名：`Exclusive Locks`，简称`X锁`。在事务要改动一条记录时，需要先获取该记录的`X锁`。FOR UPDATE

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922194321928.png)



#### 多粒度锁

上述的锁是行级锁，其实一个事务可以对一个表加锁，自然就被称为表级锁和表锁。对表的加锁也可以分为共享锁和独占锁

IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200922200615566.png)

##### 表级别的X锁和S锁

在对某个表执行`SELECT`、`INSERT`、`DELETE`、`UPDATE`语句时，`InnoDB`存储引擎是不会为这个表添加表级别的`S锁`或者`X锁`的。另外，在对某个表执行一些诸如`ALTER TABLE`、`DROP TABLE`这类的`DDL`语句时，其他事务对这个表并发执行诸如`SELECT`、`INSERT`、`DELETE`、`UPDATE`的语句会发生阻塞，同理，某个事务中对某个表执行`SELECT`、`INSERT`、`DELETE`、`UPDATE`语句时，在其他会话中对这个表执行`DDL`语句也会发生阻塞。这个过程其实是通过在`server层`使用一种称之为`元数据锁`（英文名：`Metadata Locks`，简称`MDL`）东东来实现的，一般情况下也不会使用`InnoDB`存储引擎自己提供的表级别的`S锁`和`X锁`。其实这个`InnoDB`存储引擎提供的表级`S锁`或者`X锁`是相当鸡肋，只会在一些特殊情况下，比方说崩溃恢复过程中用到。不过我们还是可以手动获取一下的，比方说在系统变量`autocommit=0，innodb_table_locks = 1`时，手动获取`InnoDB`存储引擎提供的表`t`的`S锁`或者`X锁`可以这么写：

- `LOCK TABLES t READ`：`InnoDB`存储引擎会对表`t`加表级别的`S锁`。
- `LOCK TABLES t WRITE`：`InnoDB`存储引擎会对表`t`加表级别的`X锁`。

不过请尽量避免在使用`InnoDB`存储引擎的表上使用`LOCK TABLES`这样的手动锁表语句，它们并不会提供什么额外的保护，只是会降低并发能力而已。

##### 表级别的IX锁和IS锁

当我们在对使用`InnoDB`存储引擎的表的某些记录加`S锁`之前，那就需要先在表级别加一个`IS锁`，当我们在对使用`InnoDB`存储引擎的表的某些记录加`X锁`之前，那就需要先在表级别加一个`IX锁`。`IS锁`和`IX锁`的使命只是为了后续在加表级别的`S锁`和`X锁`时判断表中是否有已经被加锁的记录，以避免用遍历的方式来查看表中有没有上锁的记录。

##### 表级别的`AUTO-INC锁`

系统实现这种自动给`AUTO_INCREMENT`修饰的列递增赋值的原理主要是两个：

- 采用`AUTO-INC`锁，也就是在执行插入语句时就在表级别加一个`AUTO-INC`锁，然后为每条待插入记录的`AUTO_INCREMENT`修饰的列分配递增的值，在该语句执行结束后，再把`AUTO-INC`锁释放掉。这样一个事务在持有`AUTO-INC`锁的过程中，其他事务的插入语句都要被阻塞，可以保证一个语句中分配的递增值是连续的。

  如果我们的插入语句在执行前不可以确定具体要插入多少条记录（无法预计即将插入记录的数量），比方说使用`INSERT ... SELECT`、`REPLACE ... SELECT`或者`LOAD DATA`这种插入语句，一般是使用`AUTO-INC`锁为`AUTO_INCREMENT`修饰的列生成对应的值。

- 采用一个轻量级的锁，在为插入语句生成`AUTO_INCREMENT`修饰的列的值时获取一下这个轻量级锁，然后生成本次插入语句需要用到的`AUTO_INCREMENT`列的值之后，就把该轻量级锁释放掉，并不需要等到整个插入语句执行完才释放锁。

  如果我们的插入语句在执行前就可以确定具体要插入多少条记录，比方说我们上边举的关于表`t`的例子中，在语句执行前就可以确定要插入2条记录，那么一般采用轻量级锁的方式对`AUTO_INCREMENT`修饰的列进行赋值。这种方式可以避免锁定表，可以提升插入性能。

#### InnoDB的行级锁

- Record Locks：行锁，上述所描述的锁都是这种锁，分为S锁和X锁，官方名称为LOCK_NOT_GAP
- Gap Locks：在MySQL下是可以解决幻读的，有两种解决方案。第一种就是MVCC，通过快照读，自然可以解决幻读。另外一种方案就是Gap locks。假设针对一条数据加了Gap锁，实际上就是在记录的前一条记录间加入间隙锁，加入Gap锁之后可以防止幻影插入的发生，需要注意的是Gap锁紧紧是防止插入幻影记录，并不会影响其他事务针对这条记录加行锁和Gap锁。
- Next-Key Locks：有时候我们既想锁住某条记录，又想阻止其他事务在该记录前边的`间隙`插入新记录，所以设计`InnoDB`的大叔们就提出了一种称之为`Next-Key Locks`的锁，官方的类型名称为：`LOCK_ORDINARY`，我们也可以简称为`next-key锁`，`next-key锁`的本质就是一个`正经记录锁`和一个`gap锁`的合体，它既能保护该条记录，又能阻止别的事务将新记录插入被保护记录前边的`间隙`。
- Insert Intention Locks：插入意向锁。我们说一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了所谓的`gap锁`（`next-key锁`也包含`gap锁`，后边就不强调了），如果有的话，插入操作需要等待，直到拥有`gap锁`的那个事务提交。但是设计`InnoDB`的大叔规定事务在等待的时候也需要在内存中生成一个`锁结构`，表明有事务想在某个`间隙`中插入新记录，但是现在在等待。设计`InnoDB`的大叔就把这种类型的锁命名为`Insert Intention Locks`，官方的类型名称为：`LOCK_INSERT_INTENTION`，我们也可以称为`插入意向锁`。事实上插入意向锁并不会阻止别的事务继续获取该记录上任何类型的锁。
- 隐式锁：如果一个事务A插入了一条数据，事务B请求访问数据加S锁或者X锁，此时怎么办呢？隐式锁目的是实现事务B想对记录加锁时，首先获取这条记录的事务Id，如果此时的事务id是活跃的，那么就帮忙针对这条记录创建一个X锁，自己进入等待状态。也就是别的事务在对这条记录加`S锁`或者`X锁`时，由于`隐式锁`的存在，会先帮助当前事务生成一个锁结构，然后自己再生成一个锁结构后进入等待状态。

详细的加锁信息仔细看一下我们都是小青蛙公众号



### Doublewrite

**一、脏页刷盘风险**

关于IO的最小单位：

　　1、数据库IO的最小单位是16K（MySQL默认，oracle是8K）

　　2、文件系统IO的最小单位是4K（也有1K的）

　　3、磁盘IO的最小单位是512字节

因此，存在IO写入导致page损坏的风险：

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929150927690.png)

**二、doublewrite：两次写**

提高innodb的可靠性，用来解决部分写失败(partial page write页断裂)。

1、Double write解决了什么问题

一个数据页的大小是16K，假设在把内存中的脏页写到数据库的时候，写了2K突然掉电，也就是说前2K数据是新的，后14K是旧的，那么磁盘数据库这个数据页就是不完整的，是一个坏掉的数据页。redo只能加上旧、校检完整的数据页恢复一个脏块，不能修复坏掉的数据页，所以这个数据就丢失了，可能会造成数据不一致，所以需要double write。

2、使用情景

当数据库正在从内存想磁盘写一个数据页是，数据库宕机，从而导致这个页只写了部分数据，这就是部分写失效，它会导致数据丢失。这时是无法通过重做日志恢复的，因为重做日志记录的是对页的物理修改，如果页本身已经损坏，重做日志也无能为力。

3、double write工作流程

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929150703479.png)

doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M。

1、当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中；

2、接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；

3、待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖)

4、doublewrite的崩溃恢复

如果操作系统在将页写入磁盘的过程中发生崩溃，在恢复过程中，innodb存储引擎可以从共享表空间的doublewrite中找到该页的一个最近的副本，将其复制到表空间文件，再应用redo log，就完成了恢复过程。

因为有副本所以也不担心表空间中数据页是否损坏。

Q：为什么log write不需要doublewrite的支持？

A：因为redolog写入的单位就是512字节，也就是磁盘IO的最小单位，所以无所谓数据损坏。

三、doublewrite的副作用

1、double write带来的写负载

1、double write是一个buffer, 但其实它是开在物理文件上的一个buffer, 其实也就是file, 所以它会导致系统有更多的fsync操作, 而硬盘的fsync性能是很慢的, 所以它会降低mysql的整体性能。

2、但是，doublewrite buffer写入磁盘共享表空间这个过程是连续存储，是顺序写，性能非常高，(约占写的%10)，牺牲一点写性能来保证数据页的完整还是很有必要的。

2、监控double write工作负载

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929150833244.png)


关注点：Innodb_dblwr_pages_written / Innodb_dblwr_writes



开启doublewrite后，每次脏页刷新必须要先写doublewrite，而doublewrite存在于磁盘上的是两个连续的区，每个区由连续的页组成，一般情况下一个区最多有64个页，所以一次IO写入应该可以最多写64个页。

而根据以上系统Innodb_dblwr_pages_written与Innodb_dblwr_writes的比例来看，大概在3左右，远远还没到64(如果约等于64，那么说明系统的写压力非常大，有大量的脏页要往磁盘上写)，所以从这个角度也可以看出，系统写入压力并不高。

3、关闭double write适合的场景

1、海量DML

2、不惧怕数据损坏和丢失

3、系统写负载成为主要负载

mysql> show variables like ‘%double%’;
±-------------------±------+
| Variable_name | Value |
±-------------------±------+
| innodb_doublewrite | ON |
±-------------------±------+
1 row in set (0.04 sec)
　　作为InnoDB的一个关键特性，doublewrite功能默认是开启的，但是在上述特殊的一些场景也可以视情况关闭，来提高数据库写性能。静态参数，配置文件修改，重启数据库。

4、为什么没有把double write里面的数据写到data page里面呢？

1、double write里面的数据是连续的，如果直接写到data page里面，而data page的页又是离散的，写入会很慢。

2、double write里面的数据没有办法被及时的覆盖掉，导致double write的压力很大；短时间内可能会出现double write溢出的情况。

### 主从一致性

### 如何保证主从复制数据一致性

上面说完了异步复制、半同步复制、PXC，我们回到主题：在常规的主从复制场景里，如何能保证主从数据的一致性，不要出现数据丢失等问题呢？

在MySQL中，一次事务提交后，需要写undo、写redo、写binlog，写数据文件等等。在这个过程中，可能在某个步骤发生crash，就有可能导致主从数据的不一致。为了避免这种情况，我们需要调整主从上面相关选项配置，确保即便发生crash了，也不能发生主从复制的数据丢失。

#### 1. 在master上修改配置

> ```
> innodb_flush_log_at_trx_commit = 1
> sync_binlog = 1
> ```

上述两个选项的作用是：**保证每次事务提交后，都能实时刷新到磁盘中，尤其是确保每次事务对应的binlog都能及时刷新到磁盘中**，只要有了binlog，InnoDB就有办法做数据恢复，不至于导致主从复制的数据丢失。

#### 2. 在slave上修改配置

> ```
> master_info_repository = "TABLE"
> relay_log_info_repository = "TABLE"
> relay_log_recovery = 1
> ```

上述前两个选项的作用是：**确保在slave上和复制相关的元数据表也采用InnoDB引擎，受到InnoDB事务安全的保护**，而后一个选项的作用是**开启relay log自动修复机制，发生crash时，会自动判断哪些relay log需要重新从master上抓取回来再次应用，以此避免部分数据丢失的可能性。**

通过上面几个选项的调整，就可以确保主从复制数据不会发生丢失了。但是，**这并不能保证主从数据的绝对一致性**

### 数据迁移



### 高可用



### 分库分表分区



### savepoint

底层采用undo log实现

### 分布式事务



### 索引下推

https://juejin.im/post/6844904017332535304

### MySQL中的日志

MySQL中有六种日志文件，
分别是：重做日志（redo log）、回滚日志（undo log）、二进制日志（binlog）、错误日志（errorlog）、慢查询日志（slow query log）、一般查询日志（general log），中继日志（relay log）。
其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系，这三种日志，对理解MySQL中的事务操作有着重要的意义。
这里简单总结一下这三者具有一定相关性的日志。

**重做日志（redo log）**

作用：
　　确保事务的持久性。
　　防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
内容：
　　物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。
什么时候产生：
　　事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
什么时候释放：
　　当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
对应的物理文件：
　　默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&ib_logfile2
　　innodb_log_group_home_dir 指定日志文件组所在的路径，默认./ ，表示在数据库的数据目录下。
　　innodb_log_files_in_group 指定重做日志文件组中文件的数量，默认2
　　关于文件的大小和数量，由一下两个参数配置
　　innodb_log_file_size 重做日志文件的大小。
　　innodb_mirrored_log_groups 指定了日志镜像文件组的数量，默认1
其他：
　　很重要一点，redo log是什么时候写盘的？前面说了是在事物开始之后逐步写盘的。
　　之所以说重做日志是在事务开始之后逐步写入重做日志文件，而不一定是事务提交才写入重做日志缓存，
　　原因就是，重做日志有一个缓存区Innodb_log_buffer，Innodb_log_buffer的默认大小为8M(这里设置的16M),Innodb存储引擎先将重做日志写入innodb_log_buffer中。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929151644389.png)

　　然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘
　　1，Master Thread 每秒一次执行刷新Innodb_log_buffer到重做日志文件。
　　2，每个事务提交时会将重做日志刷新到重做日志文件。
　　3，当重做日志缓存可用空间 少于一半时，重做日志缓存被刷新到重做日志文件
　　由此可以看出，重做日志通过不止一种方式写入到磁盘，尤其是对于第一种方式，Innodb_log_buffer到重做日志文件是Master Thread线程的定时任务。
　　因此重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。
　　另外引用《MySQL技术内幕 Innodb 存储引擎》（page37）上的原话：
　　即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。
　　这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。


**回滚日志（undo log）**

作用：
　　保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

内容：
　　逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

什么时候产生：
　　事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性

什么时候释放：
　　当事务提交之后，undo log并不能立马被删除，
　　而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

对应的物理文件：
　　MySQL5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认的名称是ibdata，位于数据文件目录中。
　　MySQL5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数
　　如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。
　　关于MySQL5.7之后的独立undo 表空间配置参数如下
　　innodb_undo_directory = /data/undospace/ --undo独立表空间的存放目录
　　innodb_undo_logs = 128 --回滚段为128KB
　　innodb_undo_tablespaces = 4 --指定有4个undo log文件

　　如果undo使用的共享表空间，这个共享表空间中又不仅仅是存储了undo的信息，共享表空间的默认为与MySQL的数据目录下面，其属性由参数innodb_data_file_path配置。
　![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929151759184.png)

其他：
　　undo是在事务开始之前保存的被修改数据的一个版本，产生undo日志的时候，同样会伴随类似于保护事务持久化机制的redolog的产生。
　　默认情况下undo文件是保持在共享表空间的，也即ibdatafile文件中，当数据库中发生一些大的事务性操作的时候，要生成大量的undo信息，全部保存在共享表空间中的。
　　因此共享表空间可能会变的很大，默认情况下，也就是undo 日志使用共享表空间的时候，被“撑大”的共享表空间是不会也不能自动收缩的。
　　因此，mysql5.7之后的“独立undo 表空间”的配置就显得很有必要了。


**二进制日志（binlog）：**

作用：
　　1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
　　2，用于数据库的基于时间点的还原。
内容：
　　逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
　　但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，
　　也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
　　在使用mysqlbinlog解析binlog之后一些都会真相大白。
　　因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。

什么时候产生：

​		在事务执行的过程中，首先将binlog的数据写入到缓存中。

　　事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
　　这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
　　因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。
　　这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。

什么时候释放：
　　binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。
　　![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929151906797.png)

对应的物理文件：
　　配置文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定的最大的大小之后，进行滚动更新，生成新的日志文件。
　　对于每个binlog日志文件，通过一个统一的index文件来组织。

![image](https://github.com/wangjunjie0817/note/raw/master/images/image-20200929151918479.png)

其他：
　　二进制日志的作用之一是还原数据库的，这与redo log很类似，很多人混淆过，但是两者有本质的不同
　　1，作用不同：redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的（当然也可以精确到事务层面的），虽然都有还原的意思，但是其保护数据的层次是不一样的。
　　2，内容不同：redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，可以简单认为记录的就是sql语句
　　3，另外，两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的。
　　4，恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

　　关于事务提交时，redo log和binlog的写入顺序，为了保证主从复制时候的主从一致（当然也包括使用binlog进行基于时间点还原的情况），是要严格一致的，
　　MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成

### MySQL线程

https://zhuanlan.zhihu.com/p/48296142

### SQL优化

